{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f47fe84-690d-406d-8a8b-aa6276a42bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd18f1f5-1976-4075-85b6-7fa39b415b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Tables from Database file\n",
    "\n",
    "conn = sqlite3.connect('eng_subtitles_database.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce08a83-b57c-4840-91e2-84ccf322d148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the columns of Table\n",
    "cursor.execute(\"PRAGMA table_info('zipfiles')\")\n",
    "cols = cursor.fetchall()\n",
    "for col in cols:\n",
    "    print(col[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c0e35-06a6-450b-bbd7-83740c73666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Database Table inside a Pandas DataFrame\n",
    "df_raw = pd.read_sql_query(\"\"\"SELECT * FROM zipfiles\"\"\", conn)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecb1250-5e23-42b4-b19a-2dda5e33524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed28595-8025-4e2e-b167-c4d4c84bf7a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Printing content of 0th Row\n",
    "b_data = df_raw.iloc[0, 2]\n",
    "print(b_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c6875a-f9b4-4f43-a1d0-79b188c34b98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Unzipping the content of 385th row and decoding using latin-1\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "# Assuming 'content' is the binary data from your database\n",
    "binary_data = df_raw.iloc[385, 2]\n",
    "\n",
    "# Decompress the binary data using the zipfile module\n",
    "with io.BytesIO(binary_data) as f:\n",
    "    with zipfile.ZipFile(f, 'r') as zip_file:\n",
    "        # Reading only one file in the ZIP archive\n",
    "        subtitle_content = zip_file.read(zip_file.namelist()[0])\n",
    "\n",
    "# Now 'subtitle_content' should contain the extracted subtitle content\n",
    "print(subtitle_content.decode('latin-1'))  # Assuming the content is latin-1 encoded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2e7ff9-9986-4f89-874a-59085c1c1580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the above Function on the Entire Data\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "count = 0\n",
    "\n",
    "def decode_method(binary_data):\n",
    "    global count\n",
    "    # Decompress the binary data using the zipfile module\n",
    "    # print(count, end=\" \")\n",
    "    count += 1\n",
    "    with io.BytesIO(binary_data) as f:\n",
    "        with zipfile.ZipFile(f, 'r') as zip_file:\n",
    "            # Assuming there's only one file in the ZIP archive\n",
    "            subtitle_content = zip_file.read(zip_file.namelist()[0])\n",
    "    \n",
    "    # Now 'subtitle_content' should contain the extracted subtitle content\n",
    "    return subtitle_content.decode('latin-1')  # Assuming the content is UTF-8 encoded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5696aedc-7abc-4a2d-b476-4e24fa597f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limited = df_raw.head(24000).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87090d0e-da1a-4e76-80a0-053e98db3b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limited['file_content'] = df_limited['content'].apply(decode_method)\n",
    "\n",
    "df_limited.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df75cdd5-d2e3-410d-be56-74e0f7b59373",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limited.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6bfd73-1bb2-4fd8-b05d-8b800adeb311",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_limited.file_content[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407d97ab-6ddf-4428-baea-89b1d88510c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_tokens_eachline(text):\n",
    "    junk_text = text\n",
    "    clean_text_step_1 = re.sub(r'\\n\\d{2}:\\d{2}:\\d{2},\\d{3} --> \\d{2}:\\d{2}:\\d{2},\\d{3}\\s+', '', junk_text)\n",
    "    clean_text_step_2 = re.sub(r'^[\\d]|\\n\\d+', '', clean_text_step_1)\n",
    "    clean_text = re.sub(r'<i>|</i>', '', clean_text_step_2)\n",
    "    return clean_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67a4c02-96fb-4ab7-9087-0b8e21e1e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tokens_oneline(text):\n",
    "    junk_text = text\n",
    "    clean_text_step_1 = re.sub(r'\\n\\d{2}:\\d{2}:\\d{2},\\d{3} --> \\d{2}:\\d{2}:\\d{2},\\d{3}\\s+', '', junk_text)\n",
    "    clean_text_step_2 = re.sub(r'^[\\d]|\\n\\d+', '', clean_text_step_1)\n",
    "    clean_text_step_3 = re.sub(r'<i>|</i>', '', clean_text_step_2)\n",
    "    clean_text = re.sub('\\r\\n\\r\\r|\\r\\n', ' ', clean_text_step_3)\n",
    "    return clean_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2641e0a8-73d5-4112-9296-cfe28c639fb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean = clean_tokens_eachline(df_limited.file_content[2])\n",
    "print(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c311721a-f659-47bb-89c1-b72b7c641aa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean = clean_tokens_oneline(df_limited.file_content[2])\n",
    "print(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b12e448-d7a2-4a51-923b-f4b2b373652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limited['Sub_Titles'] = df_limited['file_content'].apply(lambda x: clean_tokens_oneline(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639075b9-6cac-4f31-b34a-72cd24cbe5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limited['name'] = df_limited['name'].apply(lambda x: re.sub('.eng.1cd','', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44accb82-e29e-4231-b463-05fbf2257e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limited.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456ef0ae-bc6a-4d76-b8fe-8392d18723d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_limited[['num','name', 'Sub_Titles']]\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1742c769-3532-404c-8116-038b52a235aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e390f3e7-f384-4bf5-ab02-28bc7c6de254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def semantic_chunkings(document, similarity_threshold=0.9):\n",
    "    # Tokenize the document into sentences\n",
    "    sentences = document.split('.')\n",
    "    \n",
    "    # Initialize variables for semantic chunks\n",
    "    chunks = []\n",
    "    current_chunk = sentences[0]\n",
    "    \n",
    "    # Generate embeddings for the sentences\n",
    "    sentence_embeddings = model.encode(sentences)\n",
    "    \n",
    "    for i in range(1, len(sentences)):    \n",
    "        # Compute cosine similarity\n",
    "        cos_sim = util.pytorch_cos_sim(sentence_embeddings[i], sentence_embeddings[i-1])\n",
    "        if cos_sim >= similarity_threshold:\n",
    "            current_chunk += '.' + sentences[i]\n",
    "        else:\n",
    "                # If similarity score is below the threshold, start a new chunk\n",
    "                chunks.append(current_chunk)\n",
    "                current_chunk = sentences[i]\n",
    "\n",
    "    # Add the last chunk\n",
    "    chunks.append(current_chunk)\n",
    "    \n",
    "    return chunks, model.encode(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7a49b1-cde7-4057-a39f-886a76a7c342",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = semantic_chunkings(df_cleaned['Sub_Titles'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaeb0ea-2752-4f9e-810b-c75ff3a45c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ans[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be200ff-23f1-403e-a7cc-4c159f67c663",
   "metadata": {},
   "source": [
    "#### Working on Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974e5d65-f842-478e-bee8-583502ca9648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "chunks_embeddings = Parallel(n_jobs=-1)(delayed(semantic_chunkings)(item) for item in df_cleaned['Sub_Titles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69247d24-f59e-4760-8843-3dd389cd1715",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunked = pd.DataFrame(chunks_embeddings, columns=['chunks','embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20cf58d-e054-495d-9366-2cb33e77dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunked[['name', 'num']] = df_cleaned[['name', 'num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b82bb8-64c7-49a6-bcdc-4dc5535322c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444c970c-ef98-473b-a00e-c4a635a40c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to json file\n",
    "df_chunked.to_json(\"database.json\") #saving data to json file to restrart the kernel and save RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9796543b-483e-4e86-9505-0bee51708e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restarting the kernel\n",
    "# interacting with each part of the json file\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "json_file_path = \"database.json\" #database_p2.json\n",
    "with open(json_file_path, 'r') as f:\n",
    "  data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecc02e0-027f-4183-99e6-54e2ec298ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num'] = df['num'].apply(lambda x: str(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72771a7c-ad42-439a-afa6-9ae5500827ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "client = chromadb.PersistentClient(path=\"/search_engine_db\")\n",
    "collection = client.get_or_create_collection(name=\"search_engine\", metadata={\"hnsw:space\": \"cosine\"})\n",
    "collection_2 = client.get_or_create_collection(name=\"search_engine_FileName\", metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9214ed4f-f3a7-4e96-953e-bee113ae96b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexer(item):\n",
    "    index=[]\n",
    "    temp=int(df[df['num']==item].index[0])\n",
    "    for j in range(len(df['chunks'].iloc[temp])):\n",
    "        index.append(item+\"-\"+str(j))# since id needs to be unique adding the j index with a hyphen to create a unique id\n",
    "    return index\n",
    "df['num_list'] = df['num'].apply(lambda x : indexer(x)) #indexing the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a8b88-84e9-490f-a06e-ab6e754ee502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_func_v1():\n",
    "    for i in range(df.shape[0]): #setting the range as total no. of rows in dataframe\n",
    "        collection_2.add(\n",
    "            documents=[df['name'].iloc[i]], # adding each filename\n",
    "            embeddings=[[1,2,34,45]], # adding a random data, as we don't need it when retrieving file_name\n",
    "            ids=[df['num'].iloc[i]] # entering unique 'num' id\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3832ec0c-343c-4ec5-bd5b-89e15c615e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_func_v2():\n",
    "    for i in range(df.shape[0]): #setting the range as total no. of rows in dataframe\n",
    "        collection.add(\n",
    "            documents=df['chunks'].iloc[i], # adding each chunk\n",
    "            embeddings=df['embeddings'].iloc[i], # adding the corresponding chunk embedding\n",
    "            ids=df['num_list'].iloc[i] #entering the unique 'num' id\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2f66a5-69c0-453e-bf7a-d6d5059eb806",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time add_func_v1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fa7ac7-0441-4b48-8449-7cfb46ccad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time add_func_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbac9cd0-3ae4-460f-b310-b5372450347f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbfea63-359f-45b2-bc83-a71b1de84a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c443ed1-631e-4bdf-9722-d76f55dd3e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
